{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_model = Word2Vec(sentences=common_texts, window=5, min_count=1, workers=4)\n",
    "w2v_model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc2vec method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def for tagged document ->\n",
    "def tag_doc(list_of_low):\n",
    "    for i, low in enumerate(list_of_low):\n",
    "        yield gensim.models.doc2vec.TaggedDocument(low, [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data from a book: Life of James Mars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlistfromdef(sentence):\n",
    "    sentence.rstrip(\"\\n\")\n",
    "    removed = \"\"\n",
    "    for ch in sentence:\n",
    "        if ch.isalnum() or ch == \" \":\n",
    "                removed += ch.lower()\n",
    "            \n",
    "    return removed.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd', 'e']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "getlistfromdef(\"A B; c d e \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are using a window system, you might have to replace \"r\" with encoding='utf8'\n",
    "\n",
    "with open (\"Life_of_James_Mars.txt\", \"r\") as myfile:\n",
    "    file =myfile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookdata = []\n",
    "for ln in file:\n",
    "    hold = getlistfromdef(ln)\n",
    "    for wd in hold:\n",
    "        bookdata.append(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['introduction',\n",
       " 'when',\n",
       " 'i',\n",
       " 'made',\n",
       " 'up',\n",
       " 'my',\n",
       " 'mind',\n",
       " 'to',\n",
       " 'write',\n",
       " 'this',\n",
       " 'story',\n",
       " 'it',\n",
       " 'was',\n",
       " 'not',\n",
       " 'to',\n",
       " 'publish',\n",
       " 'it',\n",
       " 'but',\n",
       " 'it',\n",
       " 'was',\n",
       " 'at',\n",
       " 'the',\n",
       " 'request',\n",
       " 'of',\n",
       " 'my',\n",
       " 'sister',\n",
       " 'that',\n",
       " 'lived',\n",
       " 'in',\n",
       " 'africa',\n",
       " 'and',\n",
       " 'has',\n",
       " 'lived',\n",
       " 'there',\n",
       " 'more',\n",
       " 'than',\n",
       " 'thirty',\n",
       " 'years',\n",
       " 'she',\n",
       " 'had',\n",
       " 'heard',\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = gensim.models.Word2Vec([bookdata],min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30409, 55280)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.train([bookdata], total_examples=word2vec_model.corpus_count, epochs=word2vec_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vexed was not in the vocabulary will return error\n",
    "# word2vec_model.n_similarity(['vexed'], ['annoyed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997852"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.n_similarity(['people'], ['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99926007"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.n_similarity(['horses'], ['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think the text is a bit small and makes it hard to differentiate between words, \n",
    "# but at least  the output still works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because the text was too small and the model was not trained very well, I wanted \n",
    "# to try a different larger dataset as well as the doc2vec method\n",
    "# given dataset from gensim: text8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = api.load(\"text8\")\n",
    "data = [d for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = list(tag_doc(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_size = dimensionality of the feature\n",
    "# min_count = ignores words with lower frequency than the given\n",
    "# epoch = number of iterations \n",
    "# dm = training algorithm (1 is 'distributed memory'(PVDM), 2 is 'distributed bag of words' (DBOW))\n",
    "\n",
    "model_dbow = gensim.models.doc2vec.Doc2Vec(vector_size=40, min_count=2, epochs=30, dm=0)\n",
    "model_pvdm = gensim.models.doc2vec.Doc2Vec(vector_size=40, min_count=2, epochs=30, dm=1)\n",
    "word2vec_model = gensim.models.Word2Vec(data,min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pvdm.build_vocab(train)\n",
    "model_dbow.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pvdm.train(train, total_examples=model_pvdm.corpus_count, epochs=model_pvdm.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow.train(train, total_examples=model_dbow.corpus_count, epochs=model_dbow.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63449552, 85026035)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.train(data, total_examples=word2vec_model.corpus_count, epochs=word2vec_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0266399   0.09813191 -0.22447698  0.25955695  0.18271853 -0.04699322\n",
      "  0.14097512 -0.12786591 -0.16622266  0.2731424   0.08852278  0.06481127\n",
      "  0.04294713  0.08524445 -0.07564342  0.01464169  0.13549389 -0.11494784\n",
      " -0.11806548 -0.09634089  0.2606743   0.08735646 -0.10390906  0.25909486\n",
      "  0.02576874 -0.2787384   0.23608638  0.00932794  0.11527827  0.07946284\n",
      "  0.19009067  0.26584113 -0.16609377 -0.04089054 -0.02549952  0.13503678\n",
      " -0.2255434  -0.06137215  0.306121   -0.23324919]\n"
     ]
    }
   ],
   "source": [
    "print(model_pvdm.infer_vector(['violent', 'means', 'to', 'destroy', 'the','organization']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39376003"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test case\n",
    "model_pvdm.n_similarity(['sushi'], ['japanese'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the actual synonym detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_pvdm(key, a, b, c, d):\n",
    "    highest_similarity = 0\n",
    "    highest_word = \"\"\n",
    "    words = [a, b, c, d]\n",
    "    for w in words:\n",
    "        sim = model_pvdm.n_similarity([key], [w])\n",
    "        if sim > highest_similarity:\n",
    "            highest_similarity = sim\n",
    "            highest_word = w\n",
    "            \n",
    "    return highest_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'amused'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. vexed\n",
    "#    a. annoyed <- correct answer\n",
    "#    b. amused\n",
    "#    c. frightened\n",
    "#    d. excited\n",
    "\n",
    "synonym_pvdm('vexed', 'annoyed', 'amused', 'frightened', 'excited')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30836374"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pvdm was able to get the correct answer with a similarity score of 0.30836374\n",
    "\n",
    "model_pvdm.n_similarity(['vexed'], ['annoyed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_dbow(key, a, b, c, d):\n",
    "    highest_similarity = 0\n",
    "    highest_word = \"\"\n",
    "    words = [a, b, c, d]\n",
    "    for w in words:\n",
    "        sim = model_dbow.n_similarity([key], [w])\n",
    "        if sim > highest_similarity:\n",
    "            highest_similarity = sim\n",
    "            highest_word = w\n",
    "            \n",
    "    return highest_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'frightened'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_dbow('vexed', 'annoyed', 'amused', 'frightened', 'excited')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.072231844"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dbow got a simlarity score of: 0.072231844\n",
    "\n",
    "model_dbow.n_similarity(['vexed'], ['excited'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_w2v(key, a, b, c, d):\n",
    "    highest_similarity = 0\n",
    "    highest_word = \"\"\n",
    "    words = [a, b, c, d]\n",
    "    for w in words:\n",
    "        sim = word2vec_model.n_similarity(key, w)\n",
    "        if sim > highest_similarity:\n",
    "            highest_similarity = sim\n",
    "            highest_word = w\n",
    "            \n",
    "    return highest_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'excited'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_w2v('vexed', 'annoyed', 'amused', 'frightened', 'excited')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28602237"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#w2v got a simlarity score of: 0.28602237 (might vary )\n",
    "\n",
    "word2vec_model.n_similarity(['vexed'], ['excited'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: dbow did not do as well as pvdm probably because it uses a method that samples\n",
    "# entire phrases. On the other hand pvdm uses a method that samples specific words, \n",
    "# similar to the word2vec methods. the word2vec method also did not work well, perhaps\n",
    "# this is an issue with our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'venture'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_pvdm('enterprise', 'want', 'venture', 'offer', 'shorten')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'connection'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_pvdm('affinity', 'dispatch', 'connection', 'hoax', 'conviction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arrogant'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_pvdm('imperious', 'royal', 'friendly', 'insightful', 'arrogant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pvdm seems to work well :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
